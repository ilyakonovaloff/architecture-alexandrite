# Логирование

Логирование реализуется в каждом сервисе: `shop-api`, `CRM`, `MES` и затем агрегируется через лог-сборщик в центральное хранилище.

---

## Что логировать (INFO уровень)

### Интернет-магазин (shop-api)

| Событие                     | Поля                                                          | Описание                        |
|-----------------------------|---------------------------------------------------------------|---------------------------------|
| Добавление товара в корзину | `user_id`, `product_id`, `quantity`                           | Пользовательские действия       |
| Удаление товара из корзины  | `user_id`, `product_id`                                       | Аудит изменений                 |
| Оформление заказа           | `user_id`, `cart_contents`, `total_sum`, `payment_method`     | Ключевое бизнес-событие         |
| Подтверждение оплаты        | `order_id`, `payment_id`, `status`                            | Интеграция с платежной системой |
| Получен ответ от CRM        | `crm_endpoint`, `order_id`, `status_code`, `response_time_ms` | Мониторинг API                  |
| Изменение статуса заказа    | `order_id`, `old_status`, `new_status`                        | Прогресс заказа                 |
| Ошибка обработки заказа     | `order_id`, `error_code`, `fallback_action`                   | Когда не смогли принять заказ   |

---

### CRM

| Событие                          | Поля                                         | Описание              |
|----------------------------------|----------------------------------------------|-----------------------|
| Регистрация нового клиента       | `user_id`, `email`, `source`                 | Начало взаимодействия |
| Назначение менеджера             | `order_id`, `manager_id`                     | Процессинг            |
| Получен заказ от shop-api        | `order_id`, `status`                         | Интеграция            |
| Обновление статуса заказа        | `order_id`, `status`, `reason`               | Оперативность         |
| Ошибка синхронизации с MES       | `order_id`, `error_code`, `attempt`          | Отладка интеграции    |

---

### MES

| Событие                           | Поля                                     | Описание         |
|-----------------------------------|------------------------------------------|------------------|
| Начало производственного процесса | `order_id`, `workshop_id`, `operator_id` | Начальная стадия |
| Завершение этапа                  | `order_id`, `stage`, `duration_sec`      | Отчётность       |

---

**Все логируемые действия должны содержать:**

    * `timestamp` (в ISO 8601)
    * `service` (название сервиса)
    * `trace_id` (id трейсинга)


## Другие уровни логирования
Так же можно добавить логи следующих уровней: 

| Уровень | Примеры                                            | Назначение                     |
|---------|----------------------------------------------------|--------------------------------|
| `ERROR` | Падения, сбои, отклонения бизнес-логики            | Подлежит оповещению            |
| `DEBUG` | Детали SQL-запросов, тела сообщений                | Только в dev- или debug-режиме |
| `FATAL` | Критические сбои (например, при старте приложения) | Требует немедленного внимания  |

---

## Мотивация

Логирование — это фундаментальный компонент observability, позволяющий фиксировать ключевые действия, аномалии и состояние компонентов в системе. Без логов:

* невозможно воспроизвести инциденты;
* сложно диагностировать ошибки;
* отсутствует аудит бизнес-событий;
* падает доверие между техподдержкой и бизнесом.

### Метрики, на которые повлияет логирование

| Метрика                                              | Категория       | Как влияет логирование                                |
|------------------------------------------------------|-----------------|-------------------------------------------------------|
| **MTTR (Mean Time to Recovery)**                     | Техническая     | Снижается за счёт быстрой диагностики                 |
| **Количество инцидентов, выявленных клиентами**      | Бизнес          | Уменьшается — т.к. внутренние сбои выявляются быстрее |
| **Доля необработанных заказов в течение X минут**    | Бизнес          | Снижается — можно видеть "зависшие" статусы           |
| **Процент технических ошибок, выявленных до релиза** | Техническая     | Растёт — т.к. есть логирование в тестовой среде       |

---

### Приоритетность внедрения логирования и трейсинга

Поскольку невозможно реализовать наблюдаемость всей платформы одновременно, важно расставить приоритеты по бизнес-критичности и вероятности инцидентов.

| Система      | Почему в приоритете?                                                                                        | Что внедряем?                                                      |
|--------------|-------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------|
| **Shop API** | Основная точка контакта клиента. Ошибки здесь напрямую влияют на выручку и UX.                              | **Сначала логирование**, затем трейсинг                            |
| **CRM**      | Отвечает за бизнес-процессы, маршрутизацию заказов. Ошибки не всегда видны клиенту, но влияют на обработку. | **Сначала логирование**, затем трейсинг (чтобы связать shop → crm) |
| **MES**      | Производственная система. Важна, но ошибки здесь не влияют мгновенно на клиента.                            | **Пока только логирование**; трейсинг можно отложить               |


### В первую очередь нужно настроить:

1. **Логирование бизнес- и системных событий в Shop API и CRM** — это даст быстрый ROI (наиболее часто затрагиваемые компоненты).
2. **Трейсинг между Shop → CRM → MES** через OpenTelemetry — для полного пути заказа.

## Предлагаемое решение

Для организации логирования хорошо подойдет ELK-стек, далее будет описано, что необходимо для того, чтобы организовать логирование с использованием этого стека.

### Компоненты системы логирования ELK:

1. **Filebeat / Logstash** — агрегация логов:
    * Устанавливаются на каждый сервер.
    * Считывают логи приложений (Shop API, CRM, MES).
    * Преобразуют в структурированный формат (JSON).
    * Отправляют в Elasticsearch.

2. **Elasticsearch** — хранилище логов:
    * Централизованное индексирование и хранение логов.
    * Поддержка полнотекстового поиска и агрегаций.

3. **Kibana** — визуализация логов:
    * Дашборды и поиск по логам.
    * Настройка фильтров, алертов, панелей для DevOps/разработчиков.

---

### Что нужно внедрить или доработать

| Компонент                | Что делаем                                                             |
|--------------------------|------------------------------------------------------------------------|
| **Shop API / CRM / MES** | Обеспечить логирование в stdout/stderr в JSON-формате с нужными полями |
| **Filebeat**             | Установить в каждый сервер                                             |
| **Logstash**             | Для предварительной фильтрации, анонимизации, обогащения               |
| **Elasticsearch**        | Настроить кластеры, индексы по системам, ретеншн                       |
| **Kibana**               | Настроить дашборды, права доступа по ролям                             |

---

### Политика безопасности в отношении логов

1. **Аутентификация и авторизация**:

    Настроить аутентификацию через корпоративный Identity Provider (например, Keycloak, либо SSO через OAuth/SAML). Доступ разрешён только ролям **Поддержка**, **DevOps**, **Разработчик**.

2. **Чувствительные данные**:

    * Через Logstash реализуется маскирование/удаление:
        * Поля с номерами телефонов, email, паспортами и токенами.
        * В логах запрещено писать: пароли, номера карт, авторизационные заголовки.

---

### Политика хранения логов

| Параметр                     | Рекомендация                                                                      |
|------------------------------|-----------------------------------------------------------------------------------|
| **Индексация**               | Один индекс на систему (shop-api-logs-*, crm-logs-*, mes-logs-*)                  |
| **Ретеншн (время хранения)** | 30 дней по умолчанию, 90 дней для критичных (например, CRM)                       |
| **Сжатие**                   | Включено на уровне Elasticsearch (Lucene-level compression)                       |


[Схема](https://drive.google.com/file/d/1v3jsa-vPPDYtil27GYlyN5ol9eOv1H9k/view?usp=sharing)

---

## Система анализа логов

### Настройка алертинга

#### Что настроить:

* **Технические алерты** (на сбои, ошибки, таймауты):
    * Повышение числа HTTP 500 в логах Shop API, CRM, MES.
    * Ошибки соединения с базой (`connection refused`, `timeout`, `failed to acquire connection`).
    * Ошибки авторизации/аутентификации.
* **Бизнес-алерты**:
    * Резкое снижение количества заказов в минуту.
    * Неожиданное завершение заказов с ошибками.
    * Отсутствие логов о заказах в течение времени > N минут.

#### Технологии:

* **ElastAlert** или **Kibana Alerting**.
* Интеграция с Telegram, Slack, email, PagerDuty.

---

### Настройка поиска аномалий

#### Что считать аномалиями:

* **Резкий рост количества событий**:
    * Например: `INITIATED` обычно 5 в секунду → внезапно 5000.
    * Причины: бот-атака, нагрузочное тестирование, баг, скрипт-конкурента.
* **Резкое снижение событий**:
    * Нет заказов, хотя обычно они есть.
    * Причины: баг в UI, отказ платежного шлюза.
* **Повторяющиеся ошибки**:
    * Один и тот же стек/трассировка ошибки появляется сотни раз за минуту.

#### Технологии:

* **Machine Learning Jobs в Elastic Stack** (анализ временных рядов логов).
* **Watchers в Elasticsearch** (ручная настройка пределов).

---

### Настройка индексации логов для анализа

* **Стандартизировать структуру логов**, чтобы было удобно искать по полям:

    * `timestamp`
    * `level`
    * `service`
    * `trace_id`
    * `order_id`
    * `user_id`
    * `event_type`: `"INITIATED"`, `"PRICE_CALCULATED"`, и т.д.

---

### Визуализация: дашборды в Kibana

* Кол-во заказов/мин по API.
* Ошибки по сервисам и причинам.
* Часто повторяющиеся ошибки.
* Аномалии в поведении (всплески RPS, резкое снижение логов по бизнес-событиям).

---

### Критерии для выбора технологии для работы с логами

| № | Критерий                                       | **ELK Stack**                                                    | **OpenSearch**                         | **Grafana Loki**                          | **Splunk**                            | **Graylog**         |
|---|------------------------------------------------|------------------------------------------------------------------|----------------------------------------|-------------------------------------------|---------------------------------------|---------------------|
| 1 | **Стоимость владения (TCO)**                   | Низкая при своих серверах, но дорог при больших объёмах хранения | Низкая, оптимизирован под AWS          | Очень низкая, особенно с S3               | Очень высокая (лицензия)              | Низкая              |
| 2 | **Масштабируемость и производительность**      | Хорошая, требует тюнинга                                         | Отличная, масштабируется горизонтально | Умеренная, не оптимален для поиска        | Отличная, Enterprise-ready            | Средняя             |
| 3 | **Функциональность поиска и аналитики**        | Очень высокая, Kibana                                            | Очень высокая, Dashboards              | Умеренная, больше для потоков             | Продвинутая (AI, корреляция)          | Хорошая             |
| 4 | **Интеграции и экосистема**                    | Много плагинов, Logstash, Beats                                  | Аналогично ELK, интеграции с AWS       | Отлично интегрируется с Prometheus, Tempo | Широкий спектр, проприетарный         | Менее гибкий        |
| 5 | **Управление безопасностью и правами доступа** | Есть, но требует ручной настройки                                | Хорошая, встроена из коробки           | Ограничена, через Grafana                 | Полная (RBAC, SSO, шифрование)        | Есть базовая        |
| 6 | **Гибкость в настройке хранения**              | Поддерживает ILM, rollover                                       | ILM и hot/warm/cold storage            | Простое хранение в объектке               | Отличное, гибкое                      | Умеренная           |
| 7 | **Простота развертывания и эксплуатации**      | Сложное, ресурсоемкое                                            | Чуть проще, AWS-оптимизация            | Простое, особенно в Kubernetes            | Простое (SaaS), но сложное в изучении | Среднее             |
| 8 | **Поддержка сообществом или вендором**         | Большое OSS-сообщество                                           | Активное, AWS поддержка                | Активное (Grafana Labs)                   | Платная поддержка, отличная           | Активное сообщество |



#### Обоснование выбора ELK Stack по критериям

##### Плюсы ELK Stack

**1. Высокая функциональность поиска и аналитики**
- **Elasticsearch** – мощный поисковый движок с поддержкой полнотекстового поиска, агрегаций и сложных запросов.
- **Kibana** – удобный интерфейс для визуализации, дашбордов, анализа логов и построения отчетов.
- Поддержка **машинного обучения (Machine Learning в платной версии X-Pack)**.  

**2. Гибкость и кастомизация**
- Поддержка **разных форматов логов** (JSON, текстовые, структурированные).
- Возможность настройки **индексов, шаблонов, политик хранения (ILM)**.
- **Logstash** позволяет гибко парсить, фильтровать и обогащать данные.

**3. Масштабируемость**
- Горизонтальное масштабирование (можно добавлять узлы Elasticsearch).
- Поддержка **кластерных конфигураций** (hot-warm-cold архитектура).

**4. Интеграции и экосистема**
- **Beats (Filebeat, Metricbeat, Winlogbeat и др.)** – легковесные агенты для сбора данных.
- Поддержка **сторонних систем мониторинга** (Prometheus, Grafana, Zabbix).
- Большое количество **плагинов** для Logstash и Elasticsearch.

**5. Открытый исходный код (Open Source)**
- Бесплатная версия **ELK** (без X-Pack) подходит для большинства задач.
- Возможность развертывания **на своих серверах** без лицензионных ограничений.

---

##### Минусы ELK Stack

**1. Высокие требования к ресурсам**
- **Elasticsearch** требует много **RAM и CPU**, особенно при больших объемах данных.
- **Logstash** может быть ресурсоемким при сложных пайплайнах.

**2. Сложность настройки и эксплуатации**
- Требуется **тонкая настройка индексов, шардинга, репликации**.
- **ILM (Index Lifecycle Management)** нужно настраивать вручную.
- **Kibana** требует обучения для сложных дашбордов.

**3. Проблемы с хранением при больших объемах**
- **Высокий расход дискового пространства** (можно уменьшить через сжатие, но это влияет на производительность).
- **Hot-Warm-Cold архитектура** требует дополнительных нод.

**4. Безопасность требует ручной настройки**
- **RBAC, шифрование, аутентификация** требуют **X-Pack** (платно) или ручной настройки.

**5. Альтернативы могут быть дешевле**
- **Grafana Loki** дешевле в хранении (использует S3).
- **Graylog** проще в развертывании для базовых задач.

---

ELK Stack подходит, т.к.:  
* **Нужен мощный поиск и аналитика** (сложные запросы, агрегации).  
* **Требуется гибкость в парсинге и обработке логов** (Logstash + Filebeats).  
* **Есть ресурсы для поддержки кластера** (админы/DevOps-инженеры).  
* **Нужен open-source**.
